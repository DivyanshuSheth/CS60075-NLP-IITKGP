{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4_18QE30008.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kap77pz-OkBr"
      },
      "source": [
        "# Assignment 4 on Natural Language Processing\n",
        "\n",
        "### Instructor : Prof. Sudeshna Sarkar\n",
        "\n",
        "### Teaching Assistants : Alapan Kuila, Aniruddha Roy, Anusha Potnuru, Uppada Vishnu\n",
        "\n",
        "\n",
        "### -18QE30008, Divyanshu Sheth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZurVviTpAuwm"
      },
      "source": [
        "!rm -r sample_data\n",
        "!pip install sklearn-crfsuite 1> /dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDhHDA1Dn_ur"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from itertools import chain\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import math\n",
        "import string\n",
        "import nltk\n",
        "import sklearn\n",
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import sklearn_crfsuite\n",
        "from sklearn_crfsuite import scorers\n",
        "from sklearn_crfsuite import metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPFqT4KnukPO"
      },
      "source": [
        "data = {}\n",
        "data['train'] = pd.read_csv('hi-ud-train.conllu')\n",
        "data['test'] = pd.read_csv('hi-ud-test.conllu', sep = '\\t')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym5nzCTOlPsg",
        "outputId": "c9598bc6-53de-4505-fe6a-4b0e17637117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "print(data['train'], data['test'], sep = '\\n\\n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        ID    WORD POS_TAG\n",
            "0      1.0    yaha     DET\n",
            "1      2.0   eSiyA   PROPN\n",
            "2      3.0      kI     ADP\n",
            "3      4.0  sabase     ADV\n",
            "4      5.0   badZI     ADJ\n",
            "...    ...     ...     ...\n",
            "8105   9.0   TaMdI     ADJ\n",
            "8106  10.0      ho    VERB\n",
            "8107  11.0    jAwI     AUX\n",
            "8108  12.0      hE     AUX\n",
            "8109  13.0       .   PUNCT\n",
            "\n",
            "[8110 rows x 3 columns]\n",
            "\n",
            "        ID      WORD    TAG\n",
            "0      1.0  rAmAyaNa  PROPN\n",
            "1      2.0      kAla  PROPN\n",
            "2      3.0       meM    ADP\n",
            "3      4.0  BagavAna   NOUN\n",
            "4      5.0      rAma  PROPN\n",
            "...    ...       ...    ...\n",
            "1552  10.0     ISAna  PROPN\n",
            "1553  11.0        kA    ADP\n",
            "1554  12.0   maMxira   NOUN\n",
            "1555  13.0        hE    AUX\n",
            "1556  14.0         .  PUNCT\n",
            "\n",
            "[1557 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR0ToENGpx_-"
      },
      "source": [
        "### Features Used:<br>\n",
        "1.   The actual word itself\n",
        "2.   The length of the word- no. of characters (as shorter words are expected to be more likely to belong to a particular POS, eg. prepositions, pronouns)\n",
        "3.   The word in lowercase\n",
        "4.   Stemmed version of the word, which deletes all vowels along with g, y, n from the end of the word, but leaves at least a 2 character long stem- so that words like ‘aayenga’ do not completely vanish.\n",
        "5.   Prefixes and suffixes of the word of varying lengths\n",
        "6.   Whether or not the word is a digit\n",
        "7.   Whether or not the word is a punctuation mark\n",
        "8.   Whether the word is at the beginning of the sentence (BOS) or the end of the sentence (EOS) or neither\n",
        "9.   Features mentioned above for the previous word, the following word, and the words two places before and after\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7nQ2CftA_KF"
      },
      "source": [
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    features = {\n",
        "        'bias': 1.0,\n",
        "        'word': word,\n",
        "        'len(word)': len(word),\n",
        "        'word.lower()': word.lower(),\n",
        "        'word.stemmed': re.sub(r'(.{2,}?)([aeiougyn]+$)',r'\\1', word.lower()),\n",
        "        'word[:4]': word[:4],\n",
        "        'word[:3]': word[:3],\n",
        "        'word[:2]': word[:2],\n",
        "        'word[-3:]': word[-3:],\n",
        "        'word[-2:]': word[-2:],\n",
        "        'word[-4:]': word[-4:],\n",
        "        'word.ispunctuation': (word in string.punctuation),\n",
        "        'word.isdigit()': word.isdigit(),\n",
        "    }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        features.update({\n",
        "            '-1:word': word1,\n",
        "            '-1:len(word)': len(word1),\n",
        "            '-1:word.lower()': word1.lower(),\n",
        "            '-1:word.stemmed': re.sub(r'(.{2,}?)([aeiougyn]+$)',r'\\1', word1.lower()),\n",
        "            '-1:word[:3]': word1[:3],\n",
        "            '-1:word[:2]': word1[:2],\n",
        "            '-1:word[-3:]': word1[-3:],\n",
        "            '-1:word[-2:]': word1[-2:],\n",
        "            '-1:word.isdigit()': word1.isdigit(),\n",
        "            '-1:word.ispunctuation': (word1 in string.punctuation),\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        features['BOS'] = True\n",
        "\n",
        "    if i > 1:\n",
        "        word2 = sent[i-2][0]\n",
        "        features.update({\n",
        "            '-2:word': word2,\n",
        "            '-2:len(word)': len(word2),\n",
        "            '-2:word.lower()': word2.lower(),\n",
        "            '-2:word[:3]': word2[:3],\n",
        "            '-2:word[:2]': word2[:2],\n",
        "            '-2:word[-3:]': word2[-3:],\n",
        "            '-2:word[-2:]': word2[-2:],\n",
        "            '-2:word.isdigit()': word2.isdigit(),\n",
        "            '-2:word.ispunctuation': (word2 in string.punctuation),\n",
        "        })\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        features.update({\n",
        "            '+1:word': word1,\n",
        "            '+1:len(word)': len(word1),\n",
        "            '+1:word.lower()': word1.lower(),\n",
        "            '+1:word[:3]': word1[:3],\n",
        "            '+1:word[:2]': word1[:2],\n",
        "            '+1:word[-3:]': word1[-3:],\n",
        "            '+1:word[-2:]': word1[-2:],\n",
        "            '+1:word.isdigit()': word1.isdigit(),\n",
        "            '+1:word.ispunctuation': (word1 in string.punctuation),\n",
        "        })\n",
        "\n",
        "    else:\n",
        "        features['EOS'] = True\n",
        "\n",
        "    if i < len(sent) - 2:\n",
        "        word2 = sent[i+2][0]\n",
        "        features.update({\n",
        "            '+2:word': word2,\n",
        "            '+2:len(word)': len(word2),\n",
        "            '+2:word.lower()': word2.lower(),\n",
        "            '+2:word.stemmed': re.sub(r'(.{2,}?)([aeiougyn]+$)',r'\\1', word2.lower()),\n",
        "            '+2:word[:3]': word2[:3],\n",
        "            '+2:word[:2]': word2[:2],\n",
        "            '+2:word[-3:]': word2[-3:],\n",
        "            '+2:word[-2:]': word2[-2:],\n",
        "            '+2:word.isdigit()': word2.isdigit(),\n",
        "            '+2:word.ispunctuation': (word2 in string.punctuation),\n",
        "        })\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [word[1] for word in sent]\n",
        "\n",
        "def sent2tokens(sent):\n",
        "    return [word[0] for word in sent]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmr_K5ivQ97u"
      },
      "source": [
        "def format_data(csv_data):\n",
        "    sents = []\n",
        "    for i in range(len(csv_data)):\n",
        "        if math.isnan(csv_data.iloc[i, 0]):\n",
        "            continue\n",
        "        elif csv_data.iloc[i, 0] == 1.0:\n",
        "            sents.append([[csv_data.iloc[i, 1], csv_data.iloc[i, 2]]])\n",
        "        else:\n",
        "            sents[-1].append([csv_data.iloc[i, 1], csv_data.iloc[i, 2]])\n",
        "    for sent in sents:\n",
        "        for i, word in enumerate(sent):\n",
        "            if type(word[0]) != str:\n",
        "                del sent[i]\n",
        "    return sents"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veGT3B3QUp46"
      },
      "source": [
        "train_sents = format_data(data['train'])\n",
        "test_sents = format_data(data['test'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oos90eniOSLg"
      },
      "source": [
        "X_train = [sent2features(s) for s in train_sents]\n",
        "y_train = [sent2labels(s) for s in train_sents]\n",
        "\n",
        "X_test = [sent2features(s) for s in test_sents]\n",
        "y_test = [sent2labels(s) for s in test_sents]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OK1ke7S-iKb",
        "outputId": "6a49bcf0-1aba-40d4-e4c7-0907a2263b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%%time\n",
        "crf = sklearn_crfsuite.CRF(\n",
        "    algorithm = 'lbfgs',\n",
        "    c1 = 0.2,\n",
        "    c2 = 0.2,\n",
        "    max_iterations = 100,\n",
        "    all_possible_transitions=True\n",
        ")\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.68 s, sys: 22.1 ms, total: 3.7 s\n",
            "Wall time: 3.71 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT6QY5zt-v1t"
      },
      "source": [
        "labels = list(crf.classes_)\n",
        "labels.remove('X')\n",
        "# print(labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlsoAF1NgG2q",
        "outputId": "3b7de285-124e-49ae-a10c-be0672b4e1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "y_pred = crf.predict(X_train)\n",
        "print('F1 score on the train set = {}'.format(metrics.flat_f1_score(y_train, y_pred,\n",
        "                      average='weighted', labels=labels)))\n",
        "print('Accuracy on the train set = {}'.format(metrics.flat_accuracy_score(y_train, y_pred)))\n",
        "\n",
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print('Train set classification report: \\n\\n{}'.format(metrics.flat_classification_report(\n",
        "    y_train, y_pred, labels=sorted_labels, digits=3\n",
        ")))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on the train set = 0.9993327137643729\n",
            "Accuracy on the train set = 0.9993330665599574\n",
            "Train set classification report: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        PART      1.000     1.000     1.000       163\n",
            "       CCONJ      1.000     1.000     1.000       150\n",
            "       SCONJ      1.000     1.000     1.000        61\n",
            "         ADJ      1.000     1.000     1.000       570\n",
            "         ADP      1.000     1.000     1.000      1387\n",
            "         ADV      1.000     1.000     1.000       111\n",
            "        VERB      1.000     0.994     0.997       640\n",
            "         DET      1.000     0.996     0.998       231\n",
            "        NOUN      1.000     1.000     1.000      1597\n",
            "        PRON      0.998     1.000     0.999       431\n",
            "       PROPN      1.000     1.000     1.000       708\n",
            "         NUM      1.000     1.000     1.000       152\n",
            "       PUNCT      1.000     1.000     1.000       564\n",
            "         AUX      0.995     1.000     0.997       730\n",
            "\n",
            "   micro avg      0.999     0.999     0.999      7495\n",
            "   macro avg      0.999     0.999     0.999      7495\n",
            "weighted avg      0.999     0.999     0.999      7495\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n4buehM-4cw",
        "outputId": "55e87076-6a2d-4715-ed94-6a1a8eff06e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "y_pred = crf.predict(X_test)\n",
        "print('F1 score on the test set = {}'.format(metrics.flat_f1_score(y_test, y_pred,\n",
        "                      average='weighted', labels=labels)))\n",
        "\n",
        "print('Accuracy on the test set = {}\\n\\n'.format(metrics.flat_accuracy_score(y_test, y_pred)))\n",
        "\n",
        "sorted_labels = sorted(\n",
        "    labels,\n",
        "    key=lambda name: (name[1:], name[0])\n",
        ")\n",
        "print('Test set classification report: \\n\\n{}'.format(metrics.flat_classification_report(\n",
        "    y_test, y_pred, labels=sorted_labels, digits=3\n",
        ")))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score on the test set = 0.8706746116675885\n",
            "Accuracy on the test set = 0.8710562414266118\n",
            "\n",
            "\n",
            "Test set classification report: \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        PART      1.000     0.879     0.935        33\n",
            "       CCONJ      1.000     1.000     1.000        25\n",
            "       SCONJ      0.667     0.667     0.667         3\n",
            "         ADJ      0.689     0.777     0.730        94\n",
            "         ADP      0.970     0.955     0.962       309\n",
            "         ADV      0.667     0.381     0.485        21\n",
            "        VERB      0.935     0.869     0.901        99\n",
            "         DET      0.838     0.861     0.849        36\n",
            "        NOUN      0.795     0.860     0.826       329\n",
            "        PRON      0.931     0.831     0.878        65\n",
            "       PROPN      0.667     0.634     0.650       145\n",
            "         NUM      0.957     0.880     0.917        25\n",
            "       PUNCT      1.000     0.993     0.996       135\n",
            "         AUX      0.965     0.978     0.971       139\n",
            "\n",
            "    accuracy                          0.871      1458\n",
            "   macro avg      0.863     0.826     0.841      1458\n",
            "weighted avg      0.873     0.871     0.871      1458\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bito4sbnVas8",
        "outputId": "af6def7a-860b-4e8b-d46a-6535e273763d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def print_transitions(trans_features):\n",
        "    for (label_from, label_to), weight in trans_features:\n",
        "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
        "\n",
        "print(\"Top likely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common(10))\n",
        "\n",
        "print(\"\\nTop unlikely transitions:\")\n",
        "print_transitions(Counter(crf.transition_features_).most_common()[-10:])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top likely transitions:\n",
            "VERB   -> AUX     3.569762\n",
            "PROPN  -> PROPN   2.304620\n",
            "ADJ    -> NOUN    1.873184\n",
            "AUX    -> SCONJ   1.670297\n",
            "AUX    -> AUX     1.622267\n",
            "NUM    -> NOUN    1.541117\n",
            "DET    -> NOUN    1.518860\n",
            "PART   -> NUM     1.495714\n",
            "VERB   -> SCONJ   1.437782\n",
            "PRON   -> ADP     1.174530\n",
            "\n",
            "Top unlikely transitions:\n",
            "VERB   -> ADJ     -0.949693\n",
            "PROPN  -> NOUN    -0.952549\n",
            "AUX    -> VERB    -0.964514\n",
            "PROPN  -> PART    -1.065034\n",
            "DET    -> ADP     -1.308058\n",
            "PROPN  -> AUX     -1.328083\n",
            "PROPN  -> DET     -1.375118\n",
            "ADJ    -> PRON    -1.427365\n",
            "VERB   -> VERB    -1.513029\n",
            "ADJ    -> ADP     -2.308780\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}